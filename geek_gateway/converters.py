# -*- coding: utf-8 -*-

# GeekGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
OpenAI <-> Kiro æ ¼å¼è½¬æ¢å™?

Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ:
- Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²
- ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
- ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° Ğ´Ğ»Ñ Kiro API
- Ğ¡Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ payload Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
"""

import json
import uuid
from typing import Any, Dict, List, Optional, Tuple, Union

from loguru import logger

from geek_gateway.config import get_internal_model_id, TOOL_DESCRIPTION_MAX_LENGTH
from geek_gateway.models import (
    ChatMessage,
    ChatCompletionRequest,
    Tool,
    ToolFunction,
    AnthropicMessage,
    AnthropicMessagesRequest,
    AnthropicTool,
    AnthropicContentBlock,
)


# ==================================================================================================
# Thinking Mode æ”¯æŒ
# ==================================================================================================

# é»˜è®¤æœ€å¤§æ€è€ƒé•¿?
DEFAULT_MAX_THINKING_LENGTH = 200000


def is_thinking_enabled(thinking_config: Optional[Union[Dict[str, Any], bool, str]]) -> bool:
    """
    æ£€?thinking æ˜¯å¦å¯ç”¨?

    æ”¯æŒå¤šç§æ ¼å¼?
    - None: æœªå¯?
    - bool: True/False
    - str: "enabled"
    - dict: {"type": "enabled", "budget_tokens": 10000}

    Args:
        thinking_config: thinking é…ç½®

    Returns:
        æ˜¯å¦å¯ç”¨ thinking
    """
    if thinking_config is None:
        return False
    if isinstance(thinking_config, bool):
        return thinking_config
    if isinstance(thinking_config, str):
        return thinking_config.lower() == "enabled"
    if isinstance(thinking_config, dict):
        type_val = str(thinking_config.get("type", "")).lower()
        if type_val == "enabled":
            return True
        budget = thinking_config.get("budget_tokens")
        if isinstance(budget, (int, float)) and budget > 0:
            return True
    return False


def get_thinking_budget(thinking_config: Optional[Union[Dict[str, Any], bool, str]]) -> int:
    """
    è·å– thinking ?token é¢„ç®—?

    Args:
        thinking_config: thinking é…ç½®

    Returns:
        token é¢„ç®—ï¼Œé»˜è®¤ä¸º DEFAULT_MAX_THINKING_LENGTH
    """
    if isinstance(thinking_config, dict):
        budget = thinking_config.get("budget_tokens")
        if isinstance(budget, (int, float)) and budget > 0:
            return int(budget)
    return DEFAULT_MAX_THINKING_LENGTH


def generate_thinking_hint(thinking_config: Optional[Union[Dict[str, Any], bool, str]]) -> str:
    """
    ç”Ÿæˆ thinking æ¨¡å¼çš„æç¤ºæ ‡ç­?

    Args:
        thinking_config: thinking é…ç½®

    Returns:
        thinking æç¤ºæ ‡ç­¾å­—ç¬¦?
    """
    budget = get_thinking_budget(thinking_config)
    return f"<thinking_mode>enabled</thinking_mode>\n<max_thinking_length>{budget}</max_thinking_length>"


def inject_thinking_hint(system_prompt: str, thinking_config: Optional[Union[Dict[str, Any], bool, str]]) -> str:
    """
    ?thinking æç¤ºæ³¨å…¥?system prompt ä¸?

    å¦‚æœ system prompt å·²ç»åŒ…å« thinking æ ‡ç­¾ï¼Œåˆ™ä¸é‡å¤æ³¨å…?

    Args:
        system_prompt: åŸå§‹ system prompt
        thinking_config: thinking é…ç½®

    Returns:
        æ³¨å…¥åçš„ system prompt
    """
    if not is_thinking_enabled(thinking_config):
        return system_prompt

    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…?thinking æ ‡ç­¾
    if "<thinking_mode>" in system_prompt or "<max_thinking_length>" in system_prompt:
        return system_prompt

    thinking_hint = generate_thinking_hint(thinking_config)

    if not system_prompt:
        return thinking_hint

    # ?thinking hint æ·»åŠ ?system prompt å¼€?
    return f"{thinking_hint}\n\n{system_prompt}"


def extract_text_content(content: Any) -> str:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ².

    OpenAI API Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ² content:
    - Ğ¡Ñ‚Ñ€Ğ¾ĞºĞ°: "Hello, world!"
    - Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº: [{"type": "text", "text": "Hello"}]
    - None: Ğ¿ÑƒÑÑ‚Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ

    Args:
        content: ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ² Ğ»ÑĞ±Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ

    Returns:
        Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°

    Example:
        >>> extract_text_content("Hello")
        'Hello'
        >>> extract_text_content([{"type": "text", "text": "World"}])
        'World'
        >>> extract_text_content(None)
        ''
    """
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
                elif "text" in item:
                    text_parts.append(item["text"])
            elif isinstance(item, str):
                text_parts.append(item)
        return "".join(text_parts)
    return str(content)


def extract_images_from_content(content: Any) -> Tuple[List[Dict[str, Any]], int]:
    """
    ä»æ¶ˆæ¯å†…å®¹ä¸­æå–å›¾ç‰‡?

    æ”¯æŒ OpenAI ?Anthropic æ ¼å¼çš„å›¾ç‰‡ï¼š
    - OpenAI: {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
    - Anthropic: {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": "..."}}

    Args:
        content: æ¶ˆæ¯å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€åˆ—è¡¨æˆ– None?

    Returns:
        Tuple[List[Dict], int]: (Kiro æ ¼å¼çš„å›¾ç‰‡åˆ—? å›¾ç‰‡æ•°é‡)
        Kiro æ ¼å¼: {"format": "png", "source": {"bytes": "base64æ•°æ®"}}
    """
    if content is None or isinstance(content, str):
        return [], 0

    if not isinstance(content, list):
        return [], 0

    images = []
    for item in content:
        if not isinstance(item, dict):
            continue

        item_type = item.get("type")

        # OpenAI æ ¼å¼: {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
        if item_type == "image_url":
            image_url = item.get("image_url", {})
            url = image_url.get("url", "")

            # è§£æ data URL
            if url.startswith("data:"):
                # æ ¼å¼: data:image/png;base64,xxxxx
                try:
                    header, data = url.split(",", 1)
                    # æå– media_typeï¼Œä¾‹ã€?image/png"
                    media_type = header.split(":")[1].split(";")[0]
                    # æå–æ ¼å¼ï¼Œä¾‹ã€?png"
                    img_format = media_type.split("/")[1] if "/" in media_type else "png"

                    images.append({
                        "format": img_format,
                        "source": {
                            "bytes": data
                        }
                    })
                    logger.debug(f"Extracted OpenAI image: format={img_format}")
                except (ValueError, IndexError) as e:
                    logger.warning(f"Failed to parse OpenAI image URL: {e}")
            else:
                # å¤–éƒ¨ URL - ç›®å‰ä¸æ”¯æŒï¼Œè®°å½•è­¦å‘Š
                logger.warning(f"External image URLs are not supported: {url[:50]}...")

        # Anthropic æ ¼å¼: {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": "..."}}
        elif item_type == "image":
            source = item.get("source", {})
            source_type = source.get("type")

            if source_type == "base64":
                media_type = source.get("media_type", "image/png")
                data = source.get("data", "")

                # æå–æ ¼å¼
                img_format = media_type.split("/")[1] if "/" in media_type else "png"

                images.append({
                    "format": img_format,
                    "source": {
                        "bytes": data
                    }
                })
                logger.debug(f"Extracted Anthropic image: format={img_format}")
            elif source_type == "url":
                # URL ç±»å‹ - ç›®å‰ä¸æ”¯?
                logger.warning(f"Image URLs are not supported: {source.get('url', '')[:50]}...")

    return images, len(images)


def merge_adjacent_messages(messages: List[ChatMessage]) -> List[ChatMessage]:
    """
    ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğ¹ Ñ€Ğ¾Ğ»ÑŒÑ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ tool messages.
    
    Kiro API Ğ½Ğµ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´Ñ€ÑĞ´ Ğ¾Ñ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ role.
    Ğ­Ñ‚Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ñ‚Ğ°ĞºĞ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ¾Ğ´Ğ½Ğ¾.
    
    Tool messages (role="tool") Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒÑÑ‚ÑÑ Ğ² user messages Ñ tool_results.
    
    Args:
        messages: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
    
    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğ¼Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸
    
    Example:
        >>> msgs = [
        ...     ChatMessage(role="user", content="Hello"),
        ...     ChatMessage(role="user", content="World")
        ... ]
        >>> merged = merge_adjacent_messages(msgs)
        >>> len(merged)
        1
        >>> merged[0].content
        'Hello\\nWorld'
    """
    if not messages:
        return []
    
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ tool messages Ğ² user messages Ñ tool_results
    processed = []
    pending_tool_results = []
    
    for msg in messages:
        if msg.role == "tool":
            # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ tool results
            tool_result = {
                "type": "tool_result",
                "tool_use_id": msg.tool_call_id or "",
                "content": extract_text_content(msg.content) or "(empty result)"
            }
            pending_tool_results.append(tool_result)
            logger.debug(f"Collected tool result for tool_call_id={msg.tool_call_id}")
        else:
            # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ğµ tool results, ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ user message Ñ Ğ½Ğ¸Ğ¼Ğ¸
            if pending_tool_results:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ user message Ñ tool_results
                tool_results_msg = ChatMessage(
                    role="user",
                    content=pending_tool_results.copy()
                )
                processed.append(tool_results_msg)
                pending_tool_results.clear()
                logger.debug(f"Created user message with {len(tool_results_msg.content)} tool results")
            
            processed.append(msg)
    
    # Ğ•ÑĞ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¸ÑÑŒ tool results Ğ² ĞºĞ¾Ğ½Ñ†Ğµ
    if pending_tool_results:
        tool_results_msg = ChatMessage(
            role="user",
            content=pending_tool_results.copy()
        )
        processed.append(tool_results_msg)
        logger.debug(f"Created final user message with {len(pending_tool_results)} tool results")
    
    # Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğ¹ Ñ€Ğ¾Ğ»ÑŒÑ
    merged = []
    for msg in processed:
        if not merged:
            merged.append(msg)
            continue
        
        last = merged[-1]
        if msg.role == last.role:
            # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
            # Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° - ÑĞ¿Ğ¸ÑĞºĞ¸, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ÑĞ¿Ğ¸ÑĞºĞ¸
            if isinstance(last.content, list) and isinstance(msg.content, list):
                last.content = last.content + msg.content
            elif isinstance(last.content, list):
                last.content = last.content + [{"type": "text", "text": extract_text_content(msg.content)}]
            elif isinstance(msg.content, list):
                last.content = [{"type": "text", "text": extract_text_content(last.content)}] + msg.content
            else:
                last_text = extract_text_content(last.content)
                current_text = extract_text_content(msg.content)
                last.content = f"{last_text}\n{current_text}"
            
            # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ tool_calls Ğ´Ğ»Ñ assistant ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
            # ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾: Ğ±ĞµĞ· ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑ€ÑÑÑ‚ÑÑ tool_calls Ğ¸Ğ· Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ³Ğ¾ Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹,
            # Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞµ 400 Ğ¾Ñ‚ Kiro API (toolResult Ğ±ĞµĞ· ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ toolUse)
            if msg.role == "assistant" and msg.tool_calls:
                if last.tool_calls is None:
                    last.tool_calls = []
                last.tool_calls = list(last.tool_calls) + list(msg.tool_calls)
                logger.debug(f"Merged tool_calls: added {len(msg.tool_calls)} tool calls, total now: {len(last.tool_calls)}")
            
            logger.debug(f"Merged adjacent messages with role {msg.role}")
        else:
            merged.append(msg)
    
    return merged


def build_kiro_history(messages: List[ChatMessage], model_id: str) -> List[Dict[str, Any]]:
    """
    Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ Ğ¼Ğ°ÑÑĞ¸Ğ² history Ğ´Ğ»Ñ Kiro API Ğ¸Ğ· OpenAI messages.

    Kiro API Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ userInputMessage Ğ¸ assistantResponseMessage.
    Ğ­Ñ‚Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ OpenAI Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ² Kiro Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚.

    æ³¨æ„ï¼šå†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ä¼šè¢«æ›¿æ¢ä¸ºå ä½ç¬¦ï¼Œä»¥é¿å…è¯·æ±‚ä½“è¿‡å¤§?
    åªæœ‰å½“å‰æ¶ˆæ¯ï¼ˆæœ€åä¸€æ¡ï¼‰çš„å›¾ç‰‡ä¼šè¢«ä¿ç•?

    Args:
        messages: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI
        model_id: Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ ID Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Kiro

    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ»Ğ¾Ğ²Ğ°Ñ€ĞµĞ¹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ñ history Ğ² Kiro API

    Example:
        >>> msgs = [ChatMessage(role="user", content="Hello")]
        >>> history = build_kiro_history(msgs, "claude-sonnet-4")
        >>> history[0]["userInputMessage"]["content"]
        'Hello'
    """
    history = []

    for msg in messages:
        if msg.role == "user":
            # æå–æ–‡æœ¬å†…å®¹
            content = extract_text_content(msg.content)

            # æ£€æŸ¥å†å²æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰å›¾ç‰‡ï¼Œç”¨å ä½ç¬¦æ›¿ä»£
            _, image_count = extract_images_from_content(msg.content)
            if image_count > 0:
                image_placeholder = f"\n[æ­¤æ¶ˆæ¯åŒ…ã€‚{image_count} å¼ å›¾ç‰‡ï¼Œå·²åœ¨å†å²è®°å½•ä¸­çœç•¥]"
                content = content + image_placeholder if content else image_placeholder
                logger.debug(f"Replaced {image_count} image(s) with placeholder in history message")

            user_input = {
                "content": content,
                "modelId": model_id,
                "origin": "AI_EDITOR",
            }

            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° tool_results (Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° tool calls)
            tool_results = _extract_tool_results(msg.content)
            if tool_results:
                user_input["userInputMessageContext"] = {"toolResults": tool_results}

            history.append({"userInputMessage": user_input})

        elif msg.role == "assistant":
            content = extract_text_content(msg.content)

            assistant_response = {"content": content}

            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° tool_calls
            tool_uses = _extract_tool_uses(msg)
            if tool_uses:
                assistant_response["toolUses"] = tool_uses

            history.append({"assistantResponseMessage": assistant_response})

        elif msg.role == "system":
            # System prompt Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ Ğ² build_kiro_payload
            pass

    return history


def _extract_tool_results(content: Any) -> List[Dict[str, Any]]:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ tool results Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ.
    
    Args:
        content: ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ¼)
    
    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº tool results Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Kiro
    """
    tool_results = []
    
    if isinstance(content, list):
        for item in content:
            if isinstance(item, dict) and item.get("type") == "tool_result":
                tool_results.append({
                    "content": [{"text": extract_text_content(item.get("content", ""))}],
                    "status": "success",
                    "toolUseId": item.get("tool_use_id", "")
                })
    
    return tool_results


def process_tools_with_long_descriptions(
    tools: Optional[List[Tool]]
) -> Tuple[Optional[List[Tool]], str]:
    """
    ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ tools Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ descriptions.
    
    Kiro API Ğ¸Ğ¼ĞµĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ñƒ description Ğ² toolSpecification.
    Ğ•ÑĞ»Ğ¸ description Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚, Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğ² system prompt,
    Ğ° Ğ² tool Ğ¾ÑÑ‚Ğ°Ñ‘Ñ‚ÑÑ ÑÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ.
    
    Args:
        tools: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸Ğ· Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° OpenAI
    
    Returns:
        Tuple Ğ¸Ğ·:
        - Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº tools Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ descriptions (Ğ¸Ğ»Ğ¸ None ĞµÑĞ»Ğ¸ tools Ğ¿ÑƒÑÑ‚)
        - Ğ¡Ñ‚Ñ€Ğ¾ĞºĞ° Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ² system prompt (Ğ¿ÑƒÑÑ‚Ğ°Ñ ĞµÑĞ»Ğ¸ Ğ²ÑĞµ descriptions ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ)
    
    Example:
        >>> tools = [Tool(type="function", function=ToolFunction(name="bash", description="Very long..."))]
        >>> processed_tools, doc = process_tools_with_long_descriptions(tools)
        >>> "## Tool: bash" in doc
        True
    """
    if not tools:
        return None, ""
    
    # Ğ•ÑĞ»Ğ¸ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½ (0), Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ tools Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
    if TOOL_DESCRIPTION_MAX_LENGTH <= 0:
        return tools, ""
    
    tool_documentation_parts = []
    processed_tools = []
    
    for tool in tools:
        if tool.type != "function":
            processed_tools.append(tool)
            continue
        
        description = tool.function.description or ""
        
        if len(description) <= TOOL_DESCRIPTION_MAX_LENGTH:
            # Description ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ - Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
            processed_tools.append(tool)
        else:
            # Description ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ - Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼ Ğ² system prompt
            tool_name = tool.function.name
            
            logger.debug(
                f"Tool '{tool_name}' has long description ({len(description)} chars > {TOOL_DESCRIPTION_MAX_LENGTH}), "
                f"moving to system prompt"
            )
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ system prompt
            tool_documentation_parts.append(f"## Tool: {tool_name}\n\n{description}")
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ĞºĞ¾Ğ¿Ğ¸Ñ tool Ñ reference description
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Tool Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ĞºĞ¾Ğ¿Ğ¸Ğ¸
            from geek_gateway.models import ToolFunction
            
            reference_description = f"[Full documentation in system prompt under '## Tool: {tool_name}']"
            
            processed_tool = Tool(
                type=tool.type,
                function=ToolFunction(
                    name=tool.function.name,
                    description=reference_description,
                    parameters=tool.function.parameters
                )
            )
            processed_tools.append(processed_tool)
    
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²ÑƒÑ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
    tool_documentation = ""
    if tool_documentation_parts:
        tool_documentation = (
            "\n\n---\n"
            "# Tool Documentation\n"
            "The following tools have detailed documentation that couldn't fit in the tool definition.\n\n"
            + "\n\n---\n\n".join(tool_documentation_parts)
        )
    
    return processed_tools if processed_tools else None, tool_documentation


def _extract_tool_uses(msg: ChatMessage) -> List[Dict[str, Any]]:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ tool uses Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ assistant.
    
    Args:
        msg: Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ assistant
    
    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº tool uses Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Kiro
    """
    tool_uses = []
    
    # Ğ˜Ğ· Ğ¿Ğ¾Ğ»Ñ tool_calls
    if msg.tool_calls:
        for tc in msg.tool_calls:
            if isinstance(tc, dict):
                tool_uses.append({
                    "name": tc.get("function", {}).get("name", ""),
                    "input": json.loads(tc.get("function", {}).get("arguments", "{}")),
                    "toolUseId": tc.get("id", "")
                })
    
    # Ğ˜Ğ· content (ĞµÑĞ»Ğ¸ Ñ‚Ğ°Ğ¼ ĞµÑÑ‚ÑŒ tool_use)
    if isinstance(msg.content, list):
        for item in msg.content:
            if isinstance(item, dict) and item.get("type") == "tool_use":
                tool_uses.append({
                    "name": item.get("name", ""),
                    "input": item.get("input", {}),
                    "toolUseId": item.get("id", "")
                })
    
    return tool_uses


def _extract_system_and_tool_docs(
    messages: List[ChatMessage],
    tools: Optional[List[Tool]]
) -> Tuple[str, List[ChatMessage], Optional[List[Tool]]]:
    """
    æå– system prompt ?tool æ–‡æ¡£?

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        tools: å·¥å…·åˆ—è¡¨

    Returns:
        (system_prompt, non_system_messages, processed_tools)
    """
    # å¤„ç† tools ä¸­çš„?descriptions
    processed_tools, tool_documentation = process_tools_with_long_descriptions(tools)

    # æå– system prompt
    system_prompt = ""
    non_system_messages = []
    for msg in messages:
        if msg.role == "system":
            system_prompt += extract_text_content(msg.content) + "\n"
        else:
            non_system_messages.append(msg)
    system_prompt = system_prompt.strip()

    # æ·»åŠ  tool æ–‡æ¡£?system prompt
    if tool_documentation:
        system_prompt = system_prompt + tool_documentation if system_prompt else tool_documentation.strip()

    return system_prompt, non_system_messages, processed_tools


def build_kiro_payload(
    request_data: ChatCompletionRequest,
    conversation_id: str,
    profile_arn: str,
    thinking_config: Optional[Union[Dict[str, Any], bool, str]] = None
) -> dict:
    """
    Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ payload Ğ´Ğ»Ñ Kiro API.

    Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚:
    - ĞŸĞ¾Ğ»Ğ½ÑƒÑ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
    - System prompt (Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğº Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼Ñƒ user ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ)
    - Tools definitions (Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… descriptions)
    - Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
    - Thinking mode æ ‡ç­¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰

    Ğ•ÑĞ»Ğ¸ tools ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ descriptions, Ğ¾Ğ½Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
    Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑÑ‚ÑÑ Ğ² system prompt, Ğ° Ğ² tool Ğ¾ÑÑ‚Ğ°Ñ‘Ñ‚ÑÑ ÑÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ.

    Args:
        request_data: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI
        conversation_id: Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ID Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
        profile_arn: ARN Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ AWS CodeWhisperer
        thinking_config: Thinking æ¨¡å¼é…ç½®ï¼ˆå¯é€‰ï¼‰

    Returns:
        Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ payload Ğ´Ğ»Ñ POST Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº Kiro API

    Raises:
        ValueError: Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸
    """
    messages = list(request_data.messages)

    # ä½¿ç”¨è¾…åŠ©å‡½æ•°æå– system prompt å’Œå¤„?toolsï¼ˆä»£ç ç®€åŒ–ï¼‰
    system_prompt, non_system_messages, processed_tools = _extract_system_and_tool_docs(
        messages, request_data.tools
    )

    # æ³¨å…¥ thinking æ ‡ç­¾?system promptï¼ˆå¦‚æœå¯ç”¨ï¼‰
    system_prompt = inject_thinking_hint(system_prompt, thinking_config)

    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğ¹ Ñ€Ğ¾Ğ»ÑŒÑ
    merged_messages = merge_adjacent_messages(non_system_messages)
    
    if not merged_messages:
        raise ValueError("æ²¡æœ‰å¯å‘é€çš„æ¶ˆæ¯")
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ ID Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    model_id = get_internal_model_id(request_data.model)
    
    # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ (Ğ²ÑĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ ĞºÑ€Ğ¾Ğ¼Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾)
    history_messages = merged_messages[:-1] if len(merged_messages) > 1 else []
    
    # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ system prompt, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞµĞ³Ğ¾ Ğº Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼Ñƒ user ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    if system_prompt and history_messages:
        first_msg = history_messages[0]
        if first_msg.role == "user":
            original_content = extract_text_content(first_msg.content)
            first_msg.content = f"{system_prompt}\n\n{original_content}"
    
    history = build_kiro_history(history_messages, model_id)
    
    # Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ)
    current_message = merged_messages[-1]
    current_content = extract_text_content(current_message.content)
    
    # Ğ•ÑĞ»Ğ¸ system prompt ĞµÑÑ‚ÑŒ, Ğ½Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿ÑƒÑÑ‚Ğ° - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğº Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
    if system_prompt and not history:
        current_content = f"{system_prompt}\n\n{current_content}"
    
    # Ğ•ÑĞ»Ğ¸ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ - assistant, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞµĞ³Ğ¾ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ
    # Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ user ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ "Continue"
    if current_message.role == "assistant":
        history.append({
            "assistantResponseMessage": {
                "content": current_content
            }
        })
        current_content = "Continue"
    
    # Ğ•ÑĞ»Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
    if not current_content:
        current_content = "Continue"
    
    # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ userInputMessage
    user_input_message = {
        "content": current_content,
        "modelId": model_id,
        "origin": "AI_EDITOR",
    }

    # æå–å½“å‰æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼ˆä»…å½“å½“å‰æ¶ˆæ¯æ˜¯ user æ¶ˆæ¯æ—¶ï¼‰
    if current_message.role == "user":
        images, image_count = extract_images_from_content(current_message.content)
        if images:
            user_input_message["images"] = images
            logger.info(f"Added {image_count} image(s) to current message")

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ tools Ğ¸ tool_results ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğµ tools (Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¼Ğ¸ descriptions)
    user_input_context = _build_user_input_context(request_data, current_message, processed_tools)
    if user_input_context:
        user_input_message["userInputMessageContext"] = user_input_context
    
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ payload
    payload = {
        "conversationState": {
            "agentContinuationId": str(uuid.uuid4()),
            "agentTaskType": "vibe",
            "chatTriggerType": "MANUAL",
            "conversationId": conversation_id,
            "currentMessage": {
                "userInputMessage": user_input_message
            }
        }
    }
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ° Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ°
    if history:
        payload["conversationState"]["history"] = history
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ profileArn
    if profile_arn:
        payload["profileArn"] = profile_arn
    
    return payload


def _build_user_input_context(
    request_data: ChatCompletionRequest,
    current_message: ChatMessage,
    processed_tools: Optional[List[Tool]] = None
) -> Dict[str, Any]:
    """
    Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ userInputMessageContext Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ.
    
    Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ tools definitions Ğ¸ tool_results.
    
    Args:
        request_data: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ tools
        current_message: Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
        processed_tools: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğµ tools Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¼Ğ¸ descriptions (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾).
                        Ğ•ÑĞ»Ğ¸ None, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ tools Ğ¸Ğ· request_data.
    
    Returns:
        Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ
    """
    context = {}
    
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğµ tools ĞµÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ñ‹, Ğ¸Ğ½Ğ°Ñ‡Ğµ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ
    tools_to_use = processed_tools if processed_tools is not None else request_data.tools
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ tools ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
    if tools_to_use:
        tools_list = []
        for tool in tools_to_use:
            if tool.type == "function":
                tools_list.append({
                    "toolSpecification": {
                        "name": tool.function.name,
                        "description": tool.function.description or "",
                        "inputSchema": {"json": tool.function.parameters or {}}
                    }
                })
        if tools_list:
            context["tools"] = tools_list
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° tool_results Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸
    tool_results = _extract_tool_results(current_message.content)
    if tool_results:
        context["toolResults"] = tool_results

    return context


# ==================================================================================================
# Anthropic -> OpenAI Conversion Functions
# ==================================================================================================

def convert_anthropic_tools_to_openai(tools: Optional[List[AnthropicTool]]) -> Optional[List[Tool]]:
    """
    ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Anthropic tools Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ OpenAI.

    Anthropic Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ input_schema, OpenAI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ parameters.

    Args:
        tools: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Anthropic

    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI Ğ¸Ğ»Ğ¸ None
    """
    if not tools:
        return None

    openai_tools = []
    for tool in tools:
        openai_tool = Tool(
            type="function",
            function=ToolFunction(
                name=tool.name,
                description=tool.description,
                parameters=tool.input_schema
            )
        )
        openai_tools.append(openai_tool)

    return openai_tools


def _extract_anthropic_system_prompt(system: Optional[Any]) -> str:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ¸Ğ· Anthropic Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°.

    Args:
        system: Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ (ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²)

    Returns:
        Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ² Ğ²Ğ¸Ğ´Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
    """
    if system is None:
        return ""

    if isinstance(system, str):
        return system

    if isinstance(system, list):
        text_parts = []
        for block in system:
            if isinstance(block, dict) and block.get("type") == "text":
                text_parts.append(block.get("text", ""))
        return "\n".join(text_parts)

    return str(system)


def _convert_anthropic_content_to_openai(
    content: Any,
    _role: str  # noqa: ARG001 - ä¿ç•™å‚æ•°ä»¥å¤‡å°†æ¥ä½¿ç”¨
) -> Tuple[Optional[Union[str, List[Dict[str, Any]]]], Optional[List[Dict[str, Any]]], Optional[str]]:
    """
    ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Anthropic content Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ OpenAI.

    Args:
        content: Content Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Anthropic (ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²)
        role: Ğ Ğ¾Ğ»ÑŒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ (user Ğ¸Ğ»Ğ¸ assistant)

    Returns:
        Tuple Ğ¸Ğ· (text_content_or_content_list, tool_calls, tool_call_id)
        å¦‚æœå†…å®¹åŒ…å«å›¾ç‰‡ï¼Œè¿”å›åŸå§‹å†…å®¹åˆ—è¡¨ä»¥ä¿ç•™å›¾ç‰‡æ•°æ®
    """
    if isinstance(content, str):
        return content, None, None

    if not isinstance(content, list):
        return str(content) if content else None, None, None

    text_parts = []
    tool_calls = []
    tool_results = []
    has_images = False
    content_blocks = []  # ä¿ç•™åŸå§‹å†…å®¹å—ï¼ˆç”¨äºå›¾ç‰‡?

    for block in content:
        if isinstance(block, dict):
            block_type = block.get("type")

            if block_type == "text":
                text_parts.append(block.get("text", ""))
                content_blocks.append(block)

            elif block_type == "image":
                # ä¿ç•™å›¾ç‰‡æ•°æ®ï¼Œä¸è½¬æ¢ä¸ºå ä½ç¬¦
                has_images = True
                content_blocks.append(block)
                logger.debug(f"Preserving Anthropic image block")

            elif block_type == "tool_use":
                # Assistant's tool call
                tool_call = {
                    "id": block.get("id", ""),
                    "type": "function",
                    "function": {
                        "name": block.get("name", ""),
                        "arguments": json.dumps(block.get("input", {}))
                    }
                }
                tool_calls.append(tool_call)

            elif block_type == "tool_result":
                # User's tool result
                tool_result = {
                    "type": "tool_result",
                    "tool_use_id": block.get("tool_use_id", ""),
                    "content": _extract_tool_result_content(block.get("content")),
                    "is_error": block.get("is_error", False)
                }
                tool_results.append(tool_result)

            elif block_type == "thinking":
                # Thinking block - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² Ñ‚ĞµĞºÑÑ‚ Ñ Ğ¿Ğ¾Ğ¼ĞµÑ‚ĞºĞ¾Ğ¹
                thinking_text = block.get("thinking", "")
                if thinking_text:
                    text_parts.append(f"<thinking>{thinking_text}</thinking>")
                    content_blocks.append({"type": "text", "text": f"<thinking>{thinking_text}</thinking>"})

        elif isinstance(block, AnthropicContentBlock):
            # Pydantic model
            if block.type == "text":
                text_parts.append(block.text or "")
                content_blocks.append({"type": "text", "text": block.text or ""})
            elif block.type == "image":
                # ä¿ç•™å›¾ç‰‡æ•°æ®
                has_images = True
                content_blocks.append({
                    "type": "image",
                    "source": block.source
                })
            elif block.type == "tool_use":
                tool_call = {
                    "id": block.id or "",
                    "type": "function",
                    "function": {
                        "name": block.name or "",
                        "arguments": json.dumps(block.input or {})
                    }
                }
                tool_calls.append(tool_call)
            elif block.type == "tool_result":
                tool_result = {
                    "type": "tool_result",
                    "tool_use_id": block.tool_use_id or "",
                    "content": _extract_tool_result_content(block.content),
                    "is_error": block.is_error or False
                }
                tool_results.append(tool_result)

    # å¦‚æœ?tool_resultsï¼Œéœ€è¦åŒæ—¶ä¿ç•™æ–‡æœ¬å†…?
    # ä¿®å¤ï¼šå³ä½¿æœ‰å·¥å…·ç»“æœä¹Ÿä¸ä¸¢å¼ƒç”¨æˆ·æ–‡æœ¬
    if tool_results:
        # å¦‚æœåŒæ—¶æœ‰æ–‡æœ¬å†…å®¹ï¼Œå°†æ–‡æœ¬å’Œ tool_results åˆå¹¶
        if text_parts:
            text_content = "\n".join(text_parts)
            # åˆ›å»ºåŒ…å«æ–‡æœ¬?tool_results çš„æ··åˆå†…?
            combined_content = [{"type": "text", "text": text_content}]
            combined_content.extend(tool_results)
            return combined_content, None, None
        return tool_results, None, None

    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œè¿”å›åŸå§‹å†…å®¹å—åˆ—è¡¨ä»¥ä¿ç•™å›¾ç‰‡æ•°æ®
    if has_images:
        return content_blocks, tool_calls if tool_calls else None, None

    text_content = "\n".join(text_parts) if text_parts else None
    return text_content, tool_calls if tool_calls else None, None


def _extract_tool_result_content(content: Any) -> str:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ¸Ğ· tool_result.

    Args:
        content: Content tool_result (ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²)

    Returns:
        Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ
    """
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and item.get("type") == "text":
                text_parts.append(item.get("text", ""))
            elif isinstance(item, str):
                text_parts.append(item)
        return "\n".join(text_parts)
    return str(content)


def convert_anthropic_messages_to_openai(
    messages: List[AnthropicMessage],
    system: Optional[Any] = None
) -> List[ChatMessage]:
    """
    ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Anthropic messages Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ OpenAI.

    Args:
        messages: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Anthropic
        system: Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)

    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI
    """
    openai_messages = []

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
    system_prompt = _extract_anthropic_system_prompt(system)
    if system_prompt:
        openai_messages.append(ChatMessage(role="system", content=system_prompt))

    for msg in messages:
        role = msg.role
        content, tool_calls, _ = _convert_anthropic_content_to_openai(msg.content, role)

        # Ğ•ÑĞ»Ğ¸ content ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ tool_results, ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ user ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ Ğ½Ğ¸Ğ¼Ğ¸
        if isinstance(content, list) and content and any(
            isinstance(c, dict) and c.get("type") == "tool_result" for c in content
        ):
            openai_messages.append(ChatMessage(
                role="user",
                content=content
            ))
        elif role == "assistant":
            openai_messages.append(ChatMessage(
                role="assistant",
                content=content or "",
                tool_calls=tool_calls
            ))
        else:
            openai_messages.append(ChatMessage(
                role="user",
                content=content or ""
            ))

    return openai_messages


def convert_anthropic_to_openai_request(
    anthropic_request: AnthropicMessagesRequest
) -> ChatCompletionRequest:
    """
    ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Anthropic MessagesRequest Ğ² OpenAI ChatCompletionRequest.

    Args:
        anthropic_request: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Anthropic

    Returns:
        Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI
    """
    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
    openai_messages = convert_anthropic_messages_to_openai(
        anthropic_request.messages,
        anthropic_request.system
    )

    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ tools
    openai_tools = convert_anthropic_tools_to_openai(anthropic_request.tools)

    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ tool_choice
    openai_tool_choice = None
    if anthropic_request.tool_choice:
        tc_type = anthropic_request.tool_choice.get("type")
        if tc_type == "auto":
            openai_tool_choice = "auto"
        elif tc_type == "any":
            openai_tool_choice = "required"
        elif tc_type == "tool":
            tool_name = anthropic_request.tool_choice.get("name")
            openai_tool_choice = {"type": "function", "function": {"name": tool_name}}
        elif tc_type == "none":
            openai_tool_choice = "none"

    # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ stop_sequences -> stop
    stop = anthropic_request.stop_sequences

    return ChatCompletionRequest(
        model=anthropic_request.model,
        messages=openai_messages,
        max_tokens=anthropic_request.max_tokens,
        temperature=anthropic_request.temperature,
        top_p=anthropic_request.top_p,
        stop=stop,
        tools=openai_tools,
        tool_choice=openai_tool_choice,
        stream=anthropic_request.stream
    )
