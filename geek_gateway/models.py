# -*- coding: utf-8 -*-

# GeekGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
OpenAI å…¼å®¹ API ?Pydantic æ¨¡å‹?

å®šä¹‰è¯·æ±‚å’Œå“åº”çš„æ•°æ®æ¨¡å¼ï¼Œæä¾›éªŒè¯å’Œåºåˆ—åŒ–åŠŸèƒ?
"""

import time
from typing import Any, Dict, List, Optional, Union
from typing_extensions import Annotated
from pydantic import BaseModel, Field


# ==================================================================================================
# /v1/models ç«¯ç‚¹æ¨¡å‹
# ==================================================================================================

class OpenAIModel(BaseModel):
    """
    OpenAI æ ¼å¼?AI æ¨¡å‹æè¿°?

    ç”¨äº /v1/models ç«¯ç‚¹çš„å“åº?
    """
    id: str
    object: str = "model"
    created: int = Field(default_factory=lambda: int(time.time()))
    owned_by: str = "anthropic"
    description: Optional[str] = None


class ModelList(BaseModel):
    """
    OpenAI æ ¼å¼çš„æ¨¡å‹åˆ—è¡?

    GET /v1/models ç«¯ç‚¹çš„å“åº?
    """
    object: str = "list"
    data: List[OpenAIModel]


# ==================================================================================================
# /v1/chat/completions ç«¯ç‚¹æ¨¡å‹
# ==================================================================================================

class ChatMessage(BaseModel):
    """
    OpenAI æ ¼å¼çš„èŠå¤©æ¶ˆæ?

    æ”¯æŒå¤šç§è§’è‰²ï¼ˆuserã€assistantã€systemã€toolï¼‰å’Œå¤šç§å†…å®¹æ ¼å¼ï¼ˆå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å¯¹è±¡ï¼‰?

    Attributes:
        role: å‘é€è€…è§’è‰²ï¼ˆuserã€assistantã€systemã€tool?
        content: æ¶ˆæ¯å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€åˆ—è¡¨æˆ– None?
        name: å¯é€‰çš„å‘é€è€…å?
        tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆç”¨?assistant?
        tool_call_id: å·¥å…·è°ƒç”¨ IDï¼ˆç”¨?tool?
    """
    role: str
    content: Optional[Union[str, List[Any], Any]] = None
    name: Optional[str] = None
    tool_calls: Optional[List[Any]] = None
    tool_call_id: Optional[str] = None
    
    model_config = {"extra": "allow"}


class ToolFunction(BaseModel):
    """
    å·¥å…·å‡½æ•°æè¿°?

    Attributes:
        name: å‡½æ•°åç§°
        description: å‡½æ•°æè¿°
        parameters: å‡½æ•°å‚æ•°?JSON Schema
    """
    name: str
    description: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None


class Tool(BaseModel):
    """
    OpenAI æ ¼å¼çš„å·¥å…?

    Attributes:
        type: å·¥å…·ç±»å‹ï¼ˆé€šå¸¸ã€?function"?
        function: å‡½æ•°æè¿°
    """
    type: str = "function"
    function: ToolFunction


class ChatCompletionRequest(BaseModel):
    """
    OpenAI Chat Completions API æ ¼å¼çš„è¯·æ±?

    æ”¯æŒæ‰€æœ‰æ ‡?OpenAI API å­—æ®µï¼ŒåŒ…æ‹¬ï¼š
    - åŸºæœ¬å‚æ•°ï¼ˆmodelã€messagesã€stream?
    - ç”Ÿæˆå‚æ•°ï¼ˆtemperatureã€top_pã€max_tokens?
    - å·¥å…·è°ƒç”¨ï¼ˆfunction calling?
    - å…¼å®¹æ€§å‚æ•°ï¼ˆæ¥å—ä½†å¿½ç•¥ï¼‰

    Attributes:
        model: ç”Ÿæˆæ¨¡å‹ ID
        messages: èŠå¤©æ¶ˆæ¯åˆ—è¡¨
        stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”ï¼ˆé»˜?False?
        temperature: ç”Ÿæˆæ¸©åº¦?-2?
        top_p: Top-p é‡‡æ ·
        n: å“åº”å˜ä½“æ•°é‡
        max_tokens: å“åº”æœ€?token ?
        max_completion_tokens: max_tokens çš„æ›¿ä»£å­—?
        stop: åœæ­¢åºåˆ—
        presence_penalty: ä¸»é¢˜é‡å¤æƒ©ç½š
        frequency_penalty: è¯æ±‡é‡å¤æƒ©ç½š
        tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
    """
    model: str
    messages: Annotated[List[ChatMessage], Field(min_length=1)]
    stream: bool = False

    # ç”Ÿæˆå‚æ•°
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    n: Optional[int] = 1
    max_tokens: Optional[int] = None
    max_completion_tokens: Optional[int] = None
    stop: Optional[Union[str, List[str]]] = None
    presence_penalty: Optional[float] = None
    frequency_penalty: Optional[float] = None

    # å·¥å…·è°ƒç”¨
    tools: Optional[List[Tool]] = None
    tool_choice: Optional[Union[str, Dict]] = None

    # å…¼å®¹æ€§å­—æ®µï¼ˆå¿½ç•¥?
    stream_options: Optional[Dict[str, Any]] = None
    logit_bias: Optional[Dict[str, float]] = None
    logprobs: Optional[bool] = None
    top_logprobs: Optional[int] = None
    user: Optional[str] = None
    seed: Optional[int] = None
    parallel_tool_calls: Optional[bool] = None

    model_config = {"extra": "allow"}


# ==================================================================================================
# å“åº”æ¨¡å‹
# ==================================================================================================

class ChatCompletionChoice(BaseModel):
    """
    Chat Completion çš„å•ä¸ªå“åº”é€‰é¡¹?

    Attributes:
        index: é€‰é¡¹ç´¢å¼•
        message: å“åº”æ¶ˆæ¯
        finish_reason: å®ŒæˆåŸå› ï¼ˆstopã€tool_callsã€length?
    """
    index: int = 0
    message: Dict[str, Any]
    finish_reason: Optional[str] = None


class ChatCompletionUsage(BaseModel):
    """
    Token ä½¿ç”¨ä¿¡æ¯?

    Attributes:
        prompt_tokens: è¯·æ±‚ token ?
        completion_tokens: å“åº” token ?
        total_tokens: ?token ?
        credits_used: ä½¿ç”¨çš„ç§¯åˆ†ï¼ˆKiro ç‰¹æœ‰?
    """
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    credits_used: Optional[float] = None


class ChatCompletionResponse(BaseModel):
    """
    Chat Completion å®Œæ•´å“åº”ï¼ˆéæµå¼ï¼?

    Attributes:
        id: å“åº”å”¯ä¸€ ID
        object: å¯¹è±¡ç±»å‹?chat.completion"?
        created: åˆ›å»ºæ—¶é—´?
        model: ä½¿ç”¨çš„æ¨¡?
        choices: å“åº”é€‰é¡¹åˆ—è¡¨
        usage: Token ä½¿ç”¨ä¿¡æ¯
    """
    id: str
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChoice]
    usage: ChatCompletionUsage


class ChatCompletionChunkDelta(BaseModel):
    """
    æµå¼ chunk çš„å¢é‡å˜åŒ?

    Attributes:
        role: è§’è‰²ï¼ˆä»…åœ¨ç¬¬ä¸€?chunk ä¸­ï¼‰
        content: æ–°å†…?
        tool_calls: æ–°çš„å·¥å…·è°ƒç”¨
    """
    role: Optional[str] = None
    content: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None


class ChatCompletionChunkChoice(BaseModel):
    """
    æµå¼ chunk ä¸­çš„å•ä¸ªé€‰é¡¹?

    Attributes:
        index: é€‰é¡¹ç´¢å¼•
        delta: å¢é‡å˜åŒ–
        finish_reason: å®ŒæˆåŸå› ï¼ˆä»…åœ¨æœ€åä¸€?chunk ä¸­ï¼‰
    """
    index: int = 0
    delta: ChatCompletionChunkDelta
    finish_reason: Optional[str] = None


class ChatCompletionChunk(BaseModel):
    """
    OpenAI æ ¼å¼çš„æµ?chunk?

    Attributes:
        id: å“åº”å”¯ä¸€ ID
        object: å¯¹è±¡ç±»å‹?chat.completion.chunk"?
        created: åˆ›å»ºæ—¶é—´?
        model: ä½¿ç”¨çš„æ¨¡?
        choices: é€‰é¡¹åˆ—è¡¨
        usage: ä½¿ç”¨ä¿¡æ¯ï¼ˆä»…åœ¨æœ€åä¸€?chunk ä¸­ï¼‰
    """
    id: str
    object: str = "chat.completion.chunk"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChunkChoice]
    usage: Optional[ChatCompletionUsage] = None


# ==================================================================================================
# Anthropic Messages API æ¨¡å‹ (/v1/messages)
# ==================================================================================================

class AnthropicContentBlock(BaseModel):
    """
    Anthropic Messages API çš„å†…å®¹å—?

    æ”¯æŒå¤šç§å†…å®¹ç±»å‹ï¼štextã€imageã€tool_useã€tool_resultã€thinking?

    Attributes:
        type: å†…å®¹ç±»å‹
        text: æ–‡æœ¬å†…å®¹ï¼ˆtype="text" æ—¶ï¼‰
        source: å›¾ç‰‡æ¥æºï¼ˆtype="image" æ—¶ï¼‰
        id: tool_use IDï¼ˆtype="tool_use" æ—¶ï¼‰
        name: å·¥å…·åç§°ï¼ˆtype="tool_use" æ—¶ï¼‰
        input: å·¥å…·è¾“å…¥æ•°æ®ï¼ˆtype="tool_use" æ—¶ï¼‰
        tool_use_id: å…³è”?tool_use IDï¼ˆtype="tool_result" æ—¶ï¼‰
        content: å·¥å…·ç»“æœï¼ˆtype="tool_result" æ—¶ï¼‰
        is_error: é”™è¯¯æ ‡å¿—ï¼ˆtype="tool_result" æ—¶ï¼‰
        thinking: thinking å†…å®¹ï¼ˆtype="thinking" æ—¶ï¼‰
    """
    type: str  # "text", "image", "tool_use", "tool_result", "thinking"
    text: Optional[str] = None
    # image fields
    source: Optional[Dict[str, Any]] = None  # {"type": "base64"/"url", "media_type": "...", "data"/"url": "..."}
    # tool_use fields
    id: Optional[str] = None
    name: Optional[str] = None
    input: Optional[Dict[str, Any]] = None
    # tool_result fields
    tool_use_id: Optional[str] = None
    content: Optional[Union[str, List[Any]]] = None
    is_error: Optional[bool] = None
    # thinking fields
    thinking: Optional[str] = None

    model_config = {"extra": "allow"}


class AnthropicMessage(BaseModel):
    """
    Anthropic æ ¼å¼çš„æ¶ˆæ?

    Attributes:
        role: è§’è‰²ï¼ˆuser ?assistant?
        content: å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–å†…å®¹å—åˆ—è¡¨?
    """
    role: str  # "user" or "assistant"
    content: Union[str, List[AnthropicContentBlock], List[Dict[str, Any]]]

    model_config = {"extra": "allow"}


class AnthropicTool(BaseModel):
    """
    Anthropic æ ¼å¼çš„å·¥å…?

    æ”¯æŒä¸¤ç§æ ¼å¼:
    1. æ ‡å‡†å·¥å…·: name + description + input_schema
    2. å†…ç½®å·¥å…·: type (?web_search_20250305) + name

    Attributes:
        name: å·¥å…·åç§°
        description: å·¥å…·æè¿°ï¼ˆå¯é€‰ï¼‰
        input_schema: è¾“å…¥å‚æ•°?JSON Schemaï¼ˆå¯é€‰ï¼Œæ ‡å‡†å·¥å…·å¿…å¡«?
        type: å·¥å…·ç±»å‹ï¼ˆå¯é€‰ï¼Œç”¨äºå†…ç½®å·¥å…·?web_search?
    """
    name: str
    description: Optional[str] = None
    input_schema: Optional[Dict[str, Any]] = None
    type: Optional[str] = None

    model_config = {"extra": "allow"}


class AnthropicMessagesRequest(BaseModel):
    """
    Anthropic Messages API è¯·æ±‚?

    Attributes:
        model: æ¨¡å‹ ID
        messages: æ¶ˆæ¯åˆ—è¡¨
        max_tokens: æœ€?token æ•°ï¼ˆå¿…å¡«?
        system: ç³»ç»Ÿæç¤º?
        tools: å·¥å…·åˆ—è¡¨
        tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
        temperature: ç”Ÿæˆæ¸©åº¦
        top_p: Top-p é‡‡æ ·
        top_k: Top-k é‡‡æ ·
        stop_sequences: åœæ­¢åºåˆ—
        stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
        metadata: è¯·æ±‚å…ƒæ•°?
        thinking: Extended thinking è®¾ç½®
    """
    model: str
    messages: Annotated[List[AnthropicMessage], Field(min_length=1)]
    max_tokens: int  # Required in Anthropic API
    system: Optional[Union[str, List[Dict[str, Any]]]] = None
    tools: Optional[List[AnthropicTool]] = None
    tool_choice: Optional[Dict[str, Any]] = None
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    top_k: Optional[int] = None
    stop_sequences: Optional[List[str]] = None
    stream: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Extended Thinking support
    thinking: Optional[Dict[str, Any]] = None  # {"type": "enabled", "budget_tokens": 1024}

    model_config = {"extra": "allow"}


class AnthropicUsage(BaseModel):
    """
    Anthropic æ ¼å¼?token ä½¿ç”¨ä¿¡æ¯?

    Attributes:
        input_tokens: è¾“å…¥ token ?
        output_tokens: è¾“å‡º token ?
    """
    input_tokens: int = 0
    output_tokens: int = 0


class AnthropicResponseContentBlock(BaseModel):
    """
    Anthropic å“åº”ä¸­çš„å†…å®¹å?

    Attributes:
        type: å†…å®¹ç±»å‹ï¼ˆtextã€tool_useã€thinking?
        text: æ–‡æœ¬å†…å®¹
        id: tool_use ID
        name: å·¥å…·åç§°
        input: å·¥å…·è¾“å…¥æ•°æ®
        thinking: thinking å†…å®¹
    """
    type: str  # "text", "tool_use", "thinking"
    text: Optional[str] = None
    id: Optional[str] = None
    name: Optional[str] = None
    input: Optional[Dict[str, Any]] = None
    thinking: Optional[str] = None


class AnthropicMessagesResponse(BaseModel):
    """
    Anthropic Messages API å“åº”?

    Attributes:
        id: å“åº”å”¯ä¸€ ID
        type: å¯¹è±¡ç±»å‹ï¼ˆå§‹ç»ˆä¸º "message"?
        role: è§’è‰²ï¼ˆå§‹ç»ˆä¸º "assistant"?
        content: å†…å®¹å—åˆ—?
        model: ä½¿ç”¨çš„æ¨¡?
        stop_reason: åœæ­¢åŸå› 
        stop_sequence: è§¦å‘çš„åœæ­¢åº?
        usage: Token ä½¿ç”¨ä¿¡æ¯
    """
    id: str
    type: str = "message"
    role: str = "assistant"
    content: List[AnthropicResponseContentBlock]
    model: str
    stop_reason: Optional[str] = None  # "end_turn", "max_tokens", "tool_use", "stop_sequence"
    stop_sequence: Optional[str] = None
    usage: AnthropicUsage