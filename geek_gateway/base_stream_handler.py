# -*- coding: utf-8 -*-

# GeekGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
æµå¼å“åº”åŸºç¡€å¤„ç†å™?

æå– OpenAI ?Anthropic æµå¼å¤„ç†çš„å…¬å…±é€»è¾‘?
å‡å°‘ä»£ç é‡å¤ï¼Œæé«˜å¯ç»´æŠ¤æ€?
"""

import asyncio
import json
import time
from abc import ABC, abstractmethod
from typing import TYPE_CHECKING, AsyncGenerator, Dict, List, Optional, Any

import httpx
from loguru import logger

from geek_gateway.parsers import AwsEventStreamParser, parse_bracket_tool_calls, deduplicate_tool_calls
from geek_gateway.config import settings
from geek_gateway.tokenizer import count_tokens, count_message_tokens, count_tools_tokens

if TYPE_CHECKING:
    from geek_gateway.auth import GeekAuthManager
    from geek_gateway.cache import ModelInfoCache

# å¯¼å…¥ debug_logger
try:
    from geek_gateway.debug_logger import debug_logger
except ImportError:
    debug_logger = None


class FirstTokenTimeoutError(Exception):
    """é¦–ä¸ª token è¶…æ—¶å¼‚å¸¸ã€?""
    pass


class BaseStreamHandler(ABC):
    """
    æµå¼å“åº”åŸºç¡€å¤„ç†å™?

    å°è£…æµå¼å¤„ç†çš„å…¬å…±é€»è¾‘?
    - é¦–ä¸ª token è¶…æ—¶å¤„ç†
    - AWS Event Stream è§£æ
    - Token è®¡æ•°
    - Tool calls å¤„ç†
    """

    def __init__(
        self,
        client: httpx.AsyncClient,
        response: httpx.Response,
        model: str,
        model_cache: "ModelInfoCache",
        auth_manager: "GeekAuthManager",
        first_token_timeout: float = settings.first_token_timeout,
        request_messages: Optional[List] = None,
        request_tools: Optional[List] = None
    ):
        """
        åˆå§‹åŒ–åŸºç¡€æµå¤„ç†å™¨?

        Args:
            client: HTTP å®¢æˆ·?
            response: HTTP å“åº”
            model: æ¨¡å‹åç§°
            model_cache: æ¨¡å‹ç¼“å­˜
            auth_manager: è®¤è¯ç®¡ç†?
            first_token_timeout: é¦–ä¸ª token è¶…æ—¶æ—¶é—´ï¼ˆç§’?
            request_messages: è¯·æ±‚æ¶ˆæ¯ï¼ˆç”¨?token è®¡æ•°?
            request_tools: è¯·æ±‚å·¥å…·ï¼ˆç”¨?token è®¡æ•°?
        """
        self.client = client
        self.response = response
        self.model = model
        self.model_cache = model_cache
        self.auth_manager = auth_manager
        self.first_token_timeout = first_token_timeout
        self.request_messages = request_messages
        self.request_tools = request_tools

        # åˆå§‹åŒ–è§£æå™¨å’ŒçŠ¶?
        self.parser = AwsEventStreamParser()
        self.completion_id = self._generate_completion_id()
        self.created_time = int(time.time())
        self.full_content = ""
        self.metering_data = None
        self.context_usage_percentage = None

    @abstractmethod
    def _generate_completion_id(self) -> str:
        """ç”Ÿæˆå®Œæˆ IDã€?""
        pass

    @abstractmethod
    def _format_content_chunk(self, content: str, first_chunk: bool) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–å†…å®¹å—?

        Args:
            content: å†…å®¹æ–‡æœ¬
            first_chunk: æ˜¯å¦ä¸ºé¦–ä¸ªå—

        Returns:
            æ ¼å¼åŒ–çš„å—æ•°?
        """
        pass

    @abstractmethod
    def _format_tool_calls_chunk(self, tool_calls: List[Dict], index: int) -> Dict[str, Any]:
        """
        æ ¼å¼?tool calls å?

        Args:
            tool_calls: tool calls åˆ—è¡¨
            index: å—ç´¢?

        Returns:
            æ ¼å¼åŒ–çš„å—æ•°?
        """
        pass

    @abstractmethod
    def _format_final_chunk(
        self,
        finish_reason: str,
        prompt_tokens: int,
        completion_tokens: int,
        total_tokens: int
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–æœ€ç»ˆå—?

        Args:
            finish_reason: å®ŒæˆåŸå› 
            prompt_tokens: è¾“å…¥ token ?
            completion_tokens: è¾“å‡º token ?
            total_tokens: ?token ?

        Returns:
            æ ¼å¼åŒ–çš„æœ€ç»ˆå—æ•°æ®
        """
        pass

    @abstractmethod
    def _serialize_chunk(self, chunk: Dict[str, Any]) -> str:
        """
        åºåˆ—åŒ–å—ä¸ºå­—ç¬¦ä¸²?

        Args:
            chunk: å—æ•°?

        Returns:
            åºåˆ—åŒ–åçš„å­—ç¬¦ä¸²
        """
        pass

    async def _read_first_chunk_with_timeout(self) -> Optional[bytes]:
        """
        è¯»å–é¦–ä¸ªå­—èŠ‚å—ï¼Œå¸¦è¶…æ—?

        Returns:
            é¦–ä¸ªå­—èŠ‚å—ï¼Œå¦‚æœä¸ºç©ºå“åº”åˆ™è¿”?None

        Raises:
            FirstTokenTimeoutError: è¶…æ—¶å¼‚å¸¸
        """
        byte_iterator = self.response.aiter_bytes()

        try:
            first_byte_chunk = await asyncio.wait_for(
                byte_iterator.__anext__(),
                timeout=self.first_token_timeout
            )
            return first_byte_chunk
        except asyncio.TimeoutError:
            logger.warning(f"First token timeout after {self.first_token_timeout}s")
            raise FirstTokenTimeoutError(f"No response within {self.first_token_timeout} seconds")
        except StopAsyncIteration:
            # ç©ºå“?- è¿™æ˜¯æ­£å¸¸?
            logger.debug("Empty response from Kiro API")
            return None

    def _process_events(self, events: List[Dict], first_chunk: bool) -> Optional[str]:
        """
        å¤„ç†è§£æçš„äº‹ä»?

        Args:
            events: äº‹ä»¶åˆ—è¡¨
            first_chunk: æ˜¯å¦ä¸ºé¦–ä¸ªå—

        Returns:
            å†…å®¹æ–‡æœ¬ï¼ˆå¦‚æœæœ‰?
        """
        content = None

        for event in events:
            if event["type"] == "content":
                content = event["data"]
                self.full_content += content
            elif event["type"] == "usage":
                self.metering_data = event["data"]
            elif event["type"] == "context_usage":
                self.context_usage_percentage = event["data"]

        return content

    def _calculate_tokens(self) -> tuple[int, int, int]:
        """
        è®¡ç®— token æ•°é‡?

        Returns:
            (prompt_tokens, completion_tokens, total_tokens)
        """
        # è®¡ç®— completion_tokensï¼ˆè¾“å‡ºï¼‰
        completion_tokens = count_tokens(self.full_content)

        # æ ¹æ®ä¸Šä¸‹æ–‡ä½¿ç”¨ç™¾åˆ†æ¯”è®¡ç®—?token ?
        total_tokens_from_api = 0
        if self.context_usage_percentage is not None and self.context_usage_percentage > 0:
            max_input_tokens = self.model_cache.get_max_input_tokens(self.model)
            total_tokens_from_api = int((self.context_usage_percentage / 100) * max_input_tokens)

        if total_tokens_from_api > 0:
            # ä½¿ç”¨ API æ•°æ®
            prompt_tokens = max(0, total_tokens_from_api - completion_tokens)
            total_tokens = total_tokens_from_api
            logger.debug(
                f"[Usage] {self.model}: "
                f"prompt_tokens={prompt_tokens} (subtraction), "
                f"completion_tokens={completion_tokens} (tiktoken), "
                f"total_tokens={total_tokens} (API Kiro)"
            )
        else:
            # ä½¿ç”¨ tiktoken è®¡ç®—
            prompt_tokens = 0
            if self.request_messages:
                prompt_tokens += count_message_tokens(self.request_messages, apply_claude_correction=False)
            if self.request_tools:
                prompt_tokens += count_tools_tokens(self.request_tools, apply_claude_correction=False)
            total_tokens = prompt_tokens + completion_tokens
            logger.debug(
                f"[Usage] {self.model}: "
                f"prompt_tokens={prompt_tokens} (tiktoken), "
                f"completion_tokens={completion_tokens} (tiktoken), "
                f"total_tokens={total_tokens} (tiktoken)"
            )

        return prompt_tokens, completion_tokens, total_tokens

    async def stream(self) -> AsyncGenerator[str, None]:
        """
        æ‰§è¡Œæµå¼å¤„ç†?

        Yields:
            åºåˆ—åŒ–çš„å—å­—ç¬¦ä¸²
        """
        try:
            # è¯»å–é¦–ä¸ª?
            first_byte_chunk = await self._read_first_chunk_with_timeout()
            if first_byte_chunk is None:
                # ç©ºå“?
                yield self._serialize_chunk({"type": "done"})
                return

            # å¤„ç†é¦–ä¸ª?
            if debug_logger:
                debug_logger.log_raw_chunk(first_byte_chunk)

            events = self.parser.feed(first_byte_chunk)
            first_content = self._process_events(events, first_chunk=True)

            first_chunk_sent = False
            if first_content:
                chunk = self._format_content_chunk(first_content, first_chunk=True)
                yield self._serialize_chunk(chunk)
                first_chunk_sent = True

            # ç»§ç»­è¯»å–å‰©ä½™?
            async for chunk in self.response.aiter_bytes():
                if debug_logger:
                    debug_logger.log_raw_chunk(chunk)

                events = self.parser.feed(chunk)
                content = self._process_events(events, first_chunk=False)

                if content:
                    chunk = self._format_content_chunk(content, first_chunk=not first_chunk_sent)
                    yield self._serialize_chunk(chunk)
                    first_chunk_sent = True

            # å¤„ç† tool calls
            bracket_tool_calls = parse_bracket_tool_calls(self.full_content)
            all_tool_calls = self.parser.get_tool_calls() + bracket_tool_calls
            all_tool_calls = deduplicate_tool_calls(all_tool_calls)

            if all_tool_calls:
                logger.debug(f"Processing {len(all_tool_calls)} tool calls for streaming response")
                for idx, tc in enumerate(all_tool_calls):
                    chunk = self._format_tool_calls_chunk([tc], idx)
                    yield self._serialize_chunk(chunk)

            # å‘é€æœ€ç»ˆå—
            finish_reason = "tool_calls" if all_tool_calls else "stop"
            prompt_tokens, completion_tokens, total_tokens = self._calculate_tokens()

            final_chunk = self._format_final_chunk(
                finish_reason,
                prompt_tokens,
                completion_tokens,
                total_tokens
            )

            if self.metering_data:
                final_chunk["usage"]["credits_used"] = self.metering_data

            yield self._serialize_chunk(final_chunk)
            yield self._serialize_chunk({"type": "done"})

        except FirstTokenTimeoutError:
            # å‘ä¸Šä¼ é€’è¶…æ—¶å¼‚å¸¸ä»¥è¿›è¡Œé‡è¯•
            raise
        except Exception as e:
            logger.error(f"Error during streaming: {e}", exc_info=True)
        finally:
            await self.response.aclose()
            logger.debug("Streaming completed")