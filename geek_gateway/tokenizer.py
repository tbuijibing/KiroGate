# -*- coding: utf-8 -*-

# GeekGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Âø?Token ËÆ°Êï∞Ê®°Âùó?

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç tiktoken (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ OpenAI –Ω–∞ Rust) –¥–ª—è –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ
–ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ö–æ–¥–∏—Ä–æ–≤–∫–∞ cl100k_base –±–ª–∏–∑–∫–∞ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ Claude.

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≠—Ç–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç, —Ç–∞–∫ –∫–∞–∫ —Ç–æ—á–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
Claude –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º. Anthropic –Ω–µ –ø—É–±–ª–∏–∫—É–µ—Ç —Å–≤–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä,
–ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è tiktoken —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.

–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ CLAUDE_CORRECTION_FACTOR = 1.15 –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞
—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö: Claude —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 15%
–±–æ–ª—å—à–µ —á–µ–º GPT-4 (cl100k_base). –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ä–∞–∑–ª–∏—á–∏—è–º–∏ –≤ BPE —Å–ª–æ–≤–∞—Ä—è—Ö.
"""

from typing import List, Dict, Any, Optional
from loguru import logger

# –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ tiktoken –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞
_encoding = None

# –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude –º–æ–¥–µ–ª–µ–π
# Claude —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 15% –±–æ–ª—å—à–µ —á–µ–º GPT-4 (cl100k_base)
# –≠—Ç–æ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å context_usage –æ—Ç API
CLAUDE_CORRECTION_FACTOR = 1.15


def _get_encoding():
    """
    –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç cl100k_base - –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è GPT-4/ChatGPT,
    –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–ª–∏–∑–∫–∞ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ Claude.
    
    Returns:
        tiktoken.Encoding –∏–ª–∏ None –µ—Å–ª–∏ tiktoken –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    """
    global _encoding
    if _encoding is None:
        try:
            import tiktoken
            _encoding = tiktoken.get_encoding("cl100k_base")
            logger.debug("[Tokenizer] Initialized tiktoken with cl100k_base encoding")
        except ImportError:
            logger.warning(
                "[Tokenizer] tiktoken not installed. "
                "Token counting will use fallback estimation. "
                "Install with: pip install tiktoken"
            )
            _encoding = False  # –ú–∞—Ä–∫–µ—Ä —á—Ç–æ –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è
        except Exception as e:
            logger.error(f"[Tokenizer] Failed to initialize tiktoken: {e}")
            _encoding = False
    return _encoding if _encoding else None


def count_tokens(text: str, apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ, —Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not text:
        return 0
    
    encoding = _get_encoding()
    if encoding:
        try:
            base_tokens = len(encoding.encode(text))
            if apply_claude_correction:
                return int(base_tokens * CLAUDE_CORRECTION_FACTOR)
            return base_tokens
        except Exception as e:
            logger.warning(f"[Tokenizer] Error encoding text: {e}")
    
    # Fallback: –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ,
    # ~2-3 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤ (–±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ ~3.5)
    # –î–ª—è Claude –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
    base_estimate = len(text) // 4 + 1
    if apply_claude_correction:
        return int(base_estimate * CLAUDE_CORRECTION_FACTOR)
    return base_estimate


def count_message_tokens(messages: List[Dict[str, Any]], apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞.
    
    –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–π OpenAI/Claude:
    - role: ~1 —Ç–æ–∫–µ–Ω
    - content: —Ç–æ–∫–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞
    - –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: ~3-4 —Ç–æ–∫–µ–Ω–∞
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude
    
    Returns:
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (—Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not messages:
        return 0
    
    total_tokens = 0
    
    for message in messages:
        # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ (role, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏)
        total_tokens += 4  # ~4 —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        # –¢–æ–∫–µ–Ω—ã —Ä–æ–ª–∏ (–±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏, —ç—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏)
        role = message.get("role", "")
        total_tokens += count_tokens(role, apply_claude_correction=False)
        
        # –¢–æ–∫–µ–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = message.get("content")
        if content:
            if isinstance(content, str):
                total_tokens += count_tokens(content, apply_claude_correction=False)
            elif isinstance(content, list):
                # –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                for item in content:
                    if isinstance(item, dict):
                        if item.get("type") == "text":
                            total_tokens += count_tokens(item.get("text", ""), apply_claude_correction=False)
                        elif item.get("type") == "image_url":
                            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞—é—Ç ~85-170 —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
                            total_tokens += 100  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞
        
        # –¢–æ–∫–µ–Ω—ã tool_calls (–µ—Å–ª–∏ –µ—Å—Ç—å)
        tool_calls = message.get("tool_calls")
        if tool_calls:
            for tc in tool_calls:
                total_tokens += 4  # –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
                func = tc.get("function", {})
                total_tokens += count_tokens(func.get("name", ""), apply_claude_correction=False)
                total_tokens += count_tokens(func.get("arguments", ""), apply_claude_correction=False)
        
        # –¢–æ–∫–µ–Ω—ã tool_call_id (–¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤)
        if message.get("tool_call_id"):
            total_tokens += count_tokens(message["tool_call_id"], apply_claude_correction=False)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
    total_tokens += 3
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
    if apply_claude_correction:
        return int(total_tokens * CLAUDE_CORRECTION_FACTOR)
    return total_tokens


def count_tools_tokens(tools: Optional[List[Dict[str, Any]]], apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude
    
    Returns:
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (—Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not tools:
        return 0
    
    total_tokens = 0
    
    for tool in tools:
        total_tokens += 4  # –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        
        if tool.get("type") == "function":
            func = tool.get("function", {})
            
            # –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏
            total_tokens += count_tokens(func.get("name", ""), apply_claude_correction=False)
            
            # –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
            total_tokens += count_tokens(func.get("description", ""), apply_claude_correction=False)
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (JSON schema)
            params = func.get("parameters")
            if params:
                import json
                params_str = json.dumps(params, ensure_ascii=False)
                total_tokens += count_tokens(params_str, apply_claude_correction=False)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
    if apply_claude_correction:
        return int(total_tokens * CLAUDE_CORRECTION_FACTOR)
    return total_tokens


def estimate_request_tokens(
    messages: List[Dict[str, Any]],
    tools: Optional[List[Dict[str, Any]]] = None,
    system_prompt: Optional[str] = None
) -> Dict[str, int]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ.
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ –≤ messages)
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ç–æ–∫–µ–Ω–æ–≤:
        - messages_tokens: —Ç–æ–∫–µ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π
        - tools_tokens: —Ç–æ–∫–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        - system_tokens: —Ç–æ–∫–µ–Ω—ã —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        - total_tokens: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    """
    messages_tokens = count_message_tokens(messages)
    tools_tokens = count_tools_tokens(tools)
    system_tokens = count_tokens(system_prompt) if system_prompt else 0
    
    return {
        "messages_tokens": messages_tokens,
        "tools_tokens": tools_tokens,
        "system_tokens": system_tokens,
        "total_tokens": messages_tokens + tools_tokens + system_tokens
    }