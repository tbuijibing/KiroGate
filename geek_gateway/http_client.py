# -*- coding: utf-8 -*-

# GeekGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
HTTP å®¢æˆ·ç«¯ç®¡ç†å™¨?

å…¨å±€ HTTP å®¢æˆ·ç«¯è¿æ¥æ± ç®¡ç†ï¼Œæé«˜æ€§èƒ½?
æ”¯æŒè‡ªé€‚åº”è¶…æ—¶ï¼Œé’ˆå¯¹æ…¢æ¨¡å‹ï¼ˆå¦‚ Opusï¼‰è‡ªåŠ¨è°ƒæ•?
æ”¯æŒ HTTP/SOCKS5 ä»£ç†é…ç½®?
"""

import asyncio
from typing import Optional
from urllib.parse import urlparse

import httpx
from fastapi import HTTPException
from loguru import logger

from geek_gateway.auth import GeekAuthManager
from geek_gateway.config import settings, get_adaptive_timeout
from geek_gateway.utils import get_kiro_headers


def _build_proxy_url() -> Optional[str]:
    """
    æ„å»ºä»£ç† URL?

    å¦‚æœé…ç½®äº†ä»£ç†è®¤è¯ä¿¡æ¯ï¼Œå°†å…¶åµŒå…¥?URL ä¸?

    Returns:
        ä»£ç† URL ?None
    """
    if not settings.proxy_url:
        return None

    proxy_url = settings.proxy_url.strip()
    if not proxy_url:
        return None

    # å¦‚æœæœ‰ç”¨æˆ·åå’Œå¯†ç ï¼ŒåµŒå…¥?URL ?
    if settings.proxy_username and settings.proxy_password:
        parsed = urlparse(proxy_url)
        # é‡æ–°æ„å»ºå¸¦è®¤è¯çš„ URL
        auth = f"{settings.proxy_username}:{settings.proxy_password}"
        if parsed.port:
            proxy_url = f"{parsed.scheme}://{auth}@{parsed.hostname}:{parsed.port}"
        else:
            proxy_url = f"{parsed.scheme}://{auth}@{parsed.hostname}"

    return proxy_url


class GlobalHTTPClientManager:
    """
    Global HTTP client manager.

    Maintains a global connection pool to avoid creating new clients for each request.
    Timeout is configured per-request, not at client level.
    """

    def __init__(self):
        """Initialize global client manager."""
        self._client: Optional[httpx.AsyncClient] = None
        self._lock = asyncio.Lock()

    async def get_client(self) -> httpx.AsyncClient:
        """
        Get or create HTTP client.

        Note: Timeout should be set per-request, not here, since the client is reused.
        Supports HTTP/SOCKS5 proxy configuration via PROXY_URL setting.

        Returns:
            HTTP client instance
        """
        async with self._lock:
            if self._client is None or self._client.is_closed:
                limits = httpx.Limits(
                    max_connections=100,
                    max_keepalive_connections=20,
                    keepalive_expiry=60.0  # Increased from 30.0 for long-running connections
                )

                # æ„å»ºä»£ç†é…ç½®
                proxy_url = _build_proxy_url()
                proxy_config = None
                if proxy_url:
                    # httpx æ”¯æŒ HTTP ?SOCKS5 ä»£ç†
                    # HTTP: http://host:port ?http://user:pass@host:port
                    # SOCKS5: socks5://host:port ?socks5://user:pass@host:port
                    proxy_config = proxy_url
                    logger.info(f"HTTP å®¢æˆ·ç«¯ä½¿ç”¨ä»£ã€?{settings.proxy_url}")

                self._client = httpx.AsyncClient(
                    timeout=None,  # Timeout set per-request
                    follow_redirects=True,
                    limits=limits,
                    http2=False,
                    proxy=proxy_config
                )
                if proxy_config:
                    logger.debug("Created new global HTTP client with proxy and connection pool")
                else:
                    logger.debug("Created new global HTTP client with connection pool")

            return self._client

    async def close(self) -> None:
        """Close global HTTP client."""
        async with self._lock:
            if self._client and not self._client.is_closed:
                await self._client.aclose()
                logger.debug("Closed global HTTP client")


# Global manager instance
global_http_client_manager = GlobalHTTPClientManager()


class GeekHttpClient:
    """
    Kiro API HTTP client with retry logic.

    Uses global connection pool for better performance.
    Automatically handles various error types:
    - 403: Auto-refresh token and retry
    - 429: Exponential backoff retry
    - 5xx: Exponential backoff retry
    - Timeout: Exponential backoff retry
    """

    def __init__(self, auth_manager: GeekAuthManager):
        """
        Initialize HTTP client.

        Args:
            auth_manager: Authentication manager
        """
        self.auth_manager = auth_manager
        self.client = None  # Will use global client

    def _extract_model_from_payload(self, json_data: Optional[dict]) -> str:
        """Extract model name from common payload locations."""
        if not json_data:
            return ""
        model = json_data.get("modelId") or json_data.get("model")
        if model:
            return model
        conversation = json_data.get("conversationState") or {}
        current = conversation.get("currentMessage") or {}
        user_input = current.get("userInputMessage") or {}
        model = user_input.get("modelId") or user_input.get("model")
        if model:
            return model
        history = conversation.get("history") or []
        for entry in reversed(history):
            user_input = entry.get("userInputMessage") if isinstance(entry, dict) else None
            if user_input and user_input.get("modelId"):
                return user_input.get("modelId")
        return ""

    async def _get_client(self) -> httpx.AsyncClient:
        """
        Get HTTP client (uses global connection pool).

        Returns:
            HTTP client instance
        """
        return await global_http_client_manager.get_client()

    async def close(self) -> None:
        """
        Close client (does not actually close global client).

        Kept for backward compatibility.
        """
        pass

    async def request_with_retry(
        self,
        method: str,
        url: str,
        json_data: dict,
        stream: bool = False,
        first_token_timeout: float = None,
        model: str = None
    ) -> httpx.Response:
        """
        Execute HTTP request with retry logic.

        Automatically handles various error types:
        - 403: Refresh token and retry
        - 429: Exponential backoff retry
        - 5xx: Exponential backoff retry
        - Timeout: Exponential backoff retry

        Args:
            method: HTTP method
            url: Request URL
            json_data: JSON request body
            stream: Whether to use streaming response
            first_token_timeout: First token timeout (streaming only)
            model: Model name (for adaptive timeout)

        Returns:
            HTTP response

        Raises:
            HTTPException: After retry failure
        """
        # ?json_data ä¸­æå–æ¨¡å‹åç§°ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if model is None:
            model = self._extract_model_from_payload(json_data)

        if stream:
            # æµå¼è¯·æ±‚ï¼šä½¿ç”¨è¾ƒé•¿çš„è¿æ¥è¶…æ—¶ï¼Œå®é™…è¯»å–è¶…æ—¶åœ¨ streaming.py ä¸­æ§?
            base_timeout = first_token_timeout or settings.first_token_timeout
            timeout = get_adaptive_timeout(model, base_timeout)
            max_retries = settings.first_token_max_retries
        else:
            # éæµå¼è¯·æ±‚ï¼šä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤ 600 ç§’ï¼‰
            base_timeout = settings.non_stream_timeout
            timeout = get_adaptive_timeout(model, base_timeout)
            max_retries = settings.max_retries

        client = await self._get_client()
        last_error = None

        for attempt in range(max_retries):
            try:
                token = await self.auth_manager.get_access_token()
                headers = self._get_headers(token)

                # Set timeout per-request
                request_timeout = httpx.Timeout(timeout)

                if stream:
                    req = client.build_request(
                        method, url, json=json_data, headers=headers, timeout=request_timeout
                    )
                    response = await client.send(req, stream=True)
                else:
                    response = await client.request(
                        method, url, json=json_data, headers=headers, timeout=request_timeout
                    )

                if response.status_code == 200:
                    return response

                # 403 - Token expired, refresh and retry
                if response.status_code == 403:
                    logger.warning(f"Received 403, refreshing token (attempt {attempt + 1}/{max_retries})")
                    await response.aclose()
                    # ä¼ é€’å½“å‰ä½¿ç”¨çš„ tokenï¼Œè®© force_refresh åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ·?
                    await self.auth_manager.force_refresh(old_token=token)
                    continue

                # 429 - Rate limited, wait and retry
                if response.status_code == 429:
                    delay = settings.base_retry_delay * (2 ** attempt)
                    logger.warning(f"Received 429, waiting {delay}s (attempt {attempt + 1}/{max_retries})")
                    await response.aclose()
                    await asyncio.sleep(delay)
                    continue

                # 5xx - Server error, wait and retry
                if 500 <= response.status_code < 600:
                    delay = settings.base_retry_delay * (2 ** attempt)
                    logger.warning(f"Received {response.status_code}, waiting {delay}s (attempt {attempt + 1}/{max_retries})")
                    await response.aclose()
                    await asyncio.sleep(delay)
                    continue

                # Other errors, return directly
                return response

            except httpx.TimeoutException as e:
                last_error = e
                if stream:
                    logger.warning(f"First token timeout after {timeout}s for model {model} (attempt {attempt + 1}/{max_retries})")
                else:
                    delay = settings.base_retry_delay * (2 ** attempt)
                    logger.warning(f"Timeout after {timeout}s for model {model}, waiting {delay}s (attempt {attempt + 1}/{max_retries})")
                    await asyncio.sleep(delay)

            except httpx.RequestError as e:
                last_error = e
                delay = settings.base_retry_delay * (2 ** attempt)
                logger.warning(f"Request error: {e}, waiting {delay}s (attempt {attempt + 1}/{max_retries})")
                await asyncio.sleep(delay)

        # All retries failed
        if stream:
            raise HTTPException(
                status_code=504,
                detail=f"æ¨¡å‹åœ?{max_retries} æ¬¡å°è¯•åä»æœªåœ?{timeout}s å†…å“åº”ï¼Œè¯·ç¨åå†è¯?
            )
        else:
            raise HTTPException(
                status_code=502,
                detail=f"åœ?{max_retries} æ¬¡å°è¯•åä»æœªå®Œæˆè¯·æ±‚: {last_error}"
            )

    def _get_headers(self, token: str) -> dict:
        """
        Build request headers.

        Args:
            token: Access token

        Returns:
            Headers dictionary
        """
        return get_kiro_headers(self.auth_manager, token)

    async def __aenter__(self) -> "GeekHttpClient":
        """Support async context manager."""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Exit context without closing global client."""
        pass


async def close_global_http_client():
    """Close global HTTP client (called on app shutdown)."""
    await global_http_client_manager.close()
